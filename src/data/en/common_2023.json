{
  "header": {
    "navbarItems": [
      {
        "name": "speakers",
        "key": "speakers"
      },
      {
        "name": "sponsors",
        "key": "sponsors"
      },
      {
        "name": "agenda",
        "key": "agenda"
      }
    ],
    "pastEvents": [2020, 2021, 2022],
    "register": "Register here",
    "registerUrl": "https://datafest23.eventbrite.co.uk"
  },
  "home": {
    "main": {
      "text": "International <span>&#x00023;DataFestival</span> in Yerevan",
      "register": "Register here",
      "scrollDown": "Scroll down",
      "eventDate": "September 8-9, 2023 at American University of Armenia"
    },
    "about": {
      "title": "What is <span>DataFest Yerevan</span>",
      "text": "DataFest Yerevan is a conference covering diverse topics in machine learning, with a strong focus on engineering and applications. It is a forum for sharing ideas and fostering collaboration.",
      "followUs": "Follow us",
      "facebookPage": "Follow us on Facebook -",
      "facebookEventPage": "Facebook event page -",
      "facebookPageUrl": "https://facebook.com/datafestYerevan",
      "facebookEventPageUrl": "https://www.facebook.com/events/6253742918081830",
      "facebookPageText": "Facebook page",
      "facebookEventText": "Facebook event",
      "youTubePageText": "YouTube page",
      "youTubeEventPageUrl": "https://www.youtube.com/@DataFestYerevan"
    }
  },
  "sponsors": {
    "title": "Our <span>Sponsors</span>",
    "generalSponsorsTitle": "<span>Gold Sponsors</span>",
    "sponsorsTitle": "<span>Silver Sponsors</span>",
    "siteSponsorsTitle": "<span>Site Sponsors</span>",
    "seeAll": "See all",
    "text": "We gratefully acknowledge the following sponsors of DataFest Yerevan 2023, whose support made this event possible",
    "aboveText": "",
    "bottomText": "",
    "generalSponsorsList": [
      {
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1690434780/datafest/DataFest%202023/Sponsors/cognaize_uvxa9a.png",
        "linkedUrl": "https://www.cognaize.com/",
        "width": "17.3em"
      },
      {
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1660224669/datafest/Datafest%202022/Sponsors/digitain_gysxxp_lwxryk.png",
        "linkedUrl": "https://www.digitain.com/",
        "width": "24.3em"
      },
      {
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1660224669/datafest/Datafest%202022/Sponsors/intent_bq2vk3_ge58ge.png",
        "linkedUrl": "https://intent.ai/",
        "width": "16.5em"
      },
      {
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1660722125/datafest/Datafest%202022/Sponsors/WorldQuant_eiwent.png",
        "linkedUrl": "https://www.worldquant.com/",
        "width": "15.2em"
      }
    ],
    "sponsorsList": [
      {
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1690435822/datafest/DataFest%202023/Sponsors/Adobe_xrizsi.png",
        "linkedUrl": "https://www.adobe.com/",
        "width": "15.2em"
      },
      {
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1660224669/datafest/Datafest%202022/Sponsors/OMD_jxxyct_d2l9io.png",
        "linkedUrl": "https://www.onetick.com/",
        "width": "24.3em"
      },
      {
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1692903163/datafest/DataFest%202023/Sponsors/plat-ai_slmqt4.png",
        "linkedUrl": "https://plat.ai/",
        "width": "14.9em"
      },
      {
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1690486638/datafest/DataFest%202023/Sponsors/SDG_zz9g1t.png",
        "linkedUrl": "https://socialdiscoverygroup.com/",
        "width": "15.2em"
      }
    ],
    "siteSponsorsList": [
      {
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1661872926/datafest/sponsors/Simply_white_logo_ugahwc.png",
        "linkedUrl": "https://www.simplytechnologies.net/",
        "width": "24.3em"
      }
    ]
  },
  "agenda": {
    "btnText": "september 8-9",
    "title": "Our <span>Agenda</span>",
    "yerevanTime": "All times are in Yerevan time (UTC+4)",
    "text": "DataFest Yerevan 2023 will be held on September 8 and 9.",
    "aboveText": "",
    "bottomText": "",
    "locations": [
      {
        "text": "Manoogian",
        "id": 0
      },
      {
        "text": "113 W",
        "id": 1
      },
      {
        "text": "114 W",
        "id": 2
      },
      {
        "text": "214 W",
        "id": 3
      },
      {
        "text": "EPIC",
        "id": 4
      }
    ],
    "days": [
      {
        "1": [
          {
            "id": 0,
            "key": "break",
            "title": "Registration",
            "roomId": 0,
            "startHour": 9,
            "startMinutes": 0,
            "endHour": 9,
            "endMinutes": 40,
            "abstract": ""
          },
          {
            "id": 10,
            "key": "break",
            "title": "Conference Opening",
            "roomId": 0,
            "startHour": 9,
            "startMinutes": 40,
            "endHour": 10,
            "endMinutes": 0,
            "abstract": ""
          },
          {
            "id": 20,
            "speaker": "Michal Valko",
            "title": "[Keynote]\nCurious World Models",
            "roomId": 0,
            "startHour": 10,
            "startMinutes": 0,
            "endHour": 11,
            "endMinutes": 0,
            "abstract": "Consider the exploration in sparse-reward or reward-free environments, such as Montezuma's Revenge. The curiosity-driven paradigm dictates an intuitive technique: At each step, the agent is rewarded for how much the realized outcome differs from their predicted outcome. However, using predictive error as intrinsic motivation is prone to fail in stochastic environments, as the agent may become hopelessly drawn to high-entropy areas of the state-action space, such as a noisy TV. Therefore it is important to distinguish between aspects of world dynamics that are inherently predictable and aspects that are inherently unpredictable: The former should constitute a source of intrinsic reward, whereas the latter should not. In this work, we study a natural solution derived from structural causal models of the world: Our key idea is to learn representations of the future that capture precisely the unpredictable aspects of each outcome -- not any more, not any less -- which we use as additional input for predictions, such that intrinsic rewards do vanish in the limit. First, we propose incorporating such hindsight representations into the agent's model to disentangle 'noise' from 'novelty', yielding Curiosity in Hindsight: a simple and scalable generalization of curiosity that is robust to all types of stochasticity. Second, we implement this framework as a drop-in modification of any prediction-based exploration bonus, and instantiate it for the recently introduced BYOL-Explore algorithm as a prime example, resulting in the noise-robust 'BYOL-Hindsight'. Third, we illustrate its behavior under various stochasticities in a grid world, and find improvements over BYOL-Explore in hard-exploration Atari games with sticky actions. Importantly, we show SOTA results in exploring Montezuma with sticky actions, while preserving performance in the non-sticky setting."
          },
          {
            "id": 30,
            "speaker": "Vahe Andonians",
            "title": "Quantization: Running Large Language Models on Resource-Constrained Platforms",
            "roomId": 1,
            "startHour": 11,
            "startMinutes": 5,
            "endHour": 11,
            "endMinutes": 35,
            "abstract": "This topic explores the concept of quantization as a means to enable the deployment of large language models on platforms with limited resources and discusses the challenges faced in running these models on resource-constrained devices."
          },
          {
            "id": 40,
            "speaker": "Armen Gabrielyan",
            "title": "Streamlining ML Deployment: Our Journey of Building an Internal ML Model Serving Library",
            "roomId": 2,
            "startHour": 11,
            "startMinutes": 5,
            "endHour": 11,
            "endMinutes": 35,
            "abstract": "Deploying ML models into production efficiently remains a significant challenge, particularly as the number of models keeps growing. In this talk, we will share our journey of developing an internal ML build tool and model serving library that streamlines the model serving, packaging and deployment process for our organization. Also, it allows us to have a seamless integration of logging and monitoring. We will discuss the lessons learned, the use cases, the technical decisions made, and the best practices applied to achieve a robust solution for serving ML models."
          },
          {
            "id": 50,
            "speaker": "Artur Kadurin",
            "title": "DL for Quantum Chemistry",
            "roomId": 4,
            "startHour": 11,
            "startMinutes": 5,
            "endHour": 11,
            "endMinutes": 35,
            "abstract": "High-level physics theory merged with modern artificial neural network architectures may begin a new era in drug discovery and materials design. Classical computational methods in quantum chemistry are expensive: it takes minutes to get the electronic properties of a single molecular geometry with an average computer. On the other hand, neural networks are prone to distributional shift and overfitting. The focus of this talk is the problem of overcoming these issues."
          },
          {
            "id": 60,
            "key": "break",
            "title": "Coffee Break",
            "roomId": 0,
            "startHour": 11,
            "startMinutes": 35,
            "endHour": 12,
            "endMinutes": 0,
            "abstract": ""
          },
          {
            "id": 70,
            "speaker": "Younes Belkada",
            "title": "Making Reinforcement Learning with Human Feedback (RLHF) more accessible with TRL and PEFT libraries",
            "roomId": 1,
            "startHour": 12,
            "startMinutes": 0,
            "endHour": 13,
            "endMinutes": 0,
            "abstract": "Reinforcement Learning with Human Feedback (RLHF) has recently emerged as an important component for building strong and reliable large language models (LLM) such as ChatGPT and Claude. With RLHF a pretrained LLM can be fine-tuned to generate answers closely aligned with human expectations. However, current RLHF pipelines require several extreme amounts of compute and GPU memory with several models in memory during training. In this talk, I will present how to effectively leverage TRL and PEFT libraries from the Hugging Face ecosystem to easily fine-tune your LLM with RLHF with low cost and on consumer-type hardware."
          },
          {
            "id": 80,
            "speaker": "Tigran Tonoyan",
            "title": "HTTP-based distributed DNN training framework",
            "roomId": 2,
            "startHour": 12,
            "startMinutes": 0,
            "endHour": 13,
            "endMinutes": 0,
            "abstract": "Training deep neural networks (DNN) was made feasible by the advancement of GPU technology, which allowed fast backpropagation in large DNN. However, backpropagation is only part of the training process. Another key component is data generation, which requires significant CPU power and I/O resources. Having all these components on the same machine may run into the bottlenecks of the system. It then may become necessary to distribute computation, especially data generation, across multiple machines. Distributed computation can also make more efficient use of computational resources; e.g., one can use the leftover CPU power of a training machine to supply data to another training on another machine (or several of them). In this talk, we will outline our approach towards distributed organization of DNN training at Krisp, and particularly, a simple, stand-alone and general distributed framework based on HTTP connections and NFS drive sharing that has helped seamless organization of distributed training and efficient load balancing on our machines. Our framework is not restricted to DNN training only and easily generalizes to more abstract job distribution scenarios across multiple machines and multiple processes."
          },
          {
            "id": 90,
            "speaker": "Philipp Seidl",
            "title": "ML for Drug Discovery",
            "roomId": 4,
            "startHour": 12,
            "startMinutes": 0,
            "endHour": 12,
            "endMinutes": 30,
            "abstract": "Activity and property prediction models are the central workhorses in drug discovery and materials sciences, but currently they have to be trained or fine-tuned for new tasks. Without training or fine-tuning, scientific language models could be used for such low-data tasks through their announced zero- and few-shot capabilities. However, their predictive quality at activity prediction is lacking. In this work, we envision a novel type of activity prediction model that is able to adapt to new prediction tasks at inference time, via understanding textual information describing the task. To this end, we propose a new architecture with separate modules for chemical and natural language inputs, and a contrastive pre-training objective on data from large biochemical databases. In extensive experiments, we show that our method CLAMP yields improved predictive performance on few-shot learning benchmarks and zero-shot problems in drug discovery. We attribute the advances of our method to the modularized architecture and to our pre-training objective."
          },
          {
            "id": 100,
            "speaker": "Philipp Guevorguian",
            "title": "Language Modeling for Chemistry ",
            "roomId": 4,
            "startHour": 12,
            "startMinutes": 35,
            "endHour": 13,
            "endMinutes": 5,
            "abstract": "The application of language models to the generation of molecular subsets across varying complexities represents a unique problem landscape that offers a direct avenue for quantifying recall, a metric otherwise inaccessible in research on large language models. The synthesis of distinct molecular sets unveils complex interplay between generative language modelling and chemical task complexity, shedding light on representations that balance specificity and generality. Furthermore, the training of generative molecular models is facilitated by self supervised training and common language model architectures, which implicitly learn representations which are simultaneously useful for downstream tasks and congruent with the understanding of human experts. To enrich molecular representations, a multimodality approach leveraging pre-trained models with scientific language understanding is being applied in order to create synergy between language models' understanding of real-life scientific experiments and the molecular language."
          },
          {
            "id": 110,
            "key": "break",
            "title": "Lunch",
            "roomId": 0,
            "startHour": 13,
            "startMinutes": 5,
            "endHour": 14,
            "endMinutes": 30,
            "abstract": ""
          },
          {
            "id": 120,
            "speaker": "Fahad Khan",
            "title": "[Keynote]\nTowards Detailed Understanding of the Visual World through Specialized Conversational Vision-Language Models",
            "roomId": 0,
            "startHour": 14,
            "startMinutes": 30,
            "endHour": 15,
            "endMinutes": 30,
            "abstract": "Machine perception that corresponds to the ability to understand the visual world based on the input from sensors, such as cameras is one of the central problems in Artificial Intelligence. To this end, recent years have witnessed tremendous progress in various instance-level recognition tasks having real-world applications in e.g., robotics, autonomous driving and surveillance. In this talk, I will first present our recent results towards understanding state-of-the-art deep learning-based visual recognition networks in terms of their robustness and generalizability. Then, I will present our recent work on a video-based conversation model, named Video-ChatGPT, that merges the representational abilities of a pretrained visual encoder and the generative powers of an LLM, capable of understanding and conversing about videos. The proposed approach aims to provide a a unified human-understandable interface to video-related tasks such as action recognition, localization, detection, segmentation, retrieval, and tracking. Our approach adapts the design for spatiotemporal video modeling and fine-tunes the model on video-instruction data to capture temporal dynamics and frame-to-frame consistency relationships available in video data. One of the key contributions of our work is the creation of a dataset of 100,000 video-instruction pairs using a combination of human-assisted and semi-automatic annotation methods. Moreover, we introduce the first quantitative video conversation evaluation framework for benchmarking, allowing for a more accurate evaluation of the performance of video conversation models. Lastly, I will also briefly discuss our ongoing work on developing specialized conversational VLMs for medical imaging domain."
          },
          {
            "id": 130,
            "speaker": "Nikita Detkov",
            "title": "State of the Text-to-Video generation and how can we use it",
            "roomId": 1,
            "startHour": 15,
            "startMinutes": 35,
            "endHour": 16,
            "endMinutes": 5,
            "abstract": "The field of Generative AI is a very popular these days because of the Text-to-Image bangers, like DALLE, Stable Diffusion and so on. But why limit ourselves to the image domain, when we can move to video? In this talk, we will give a brief overview of Text-to-Image models, make a logical transition to the Text-to-Video architectures, and discuss thier features and limitations. We will also touch on neighboring tasks, such as conditioned Video-to-Video generation and formulate the Generative Video landscape."
          },
          {
            "id": 140,
            "speaker": "Hasmik Hakobyan",
            "title": "Efficiently migrating clients' data to the cloud environment",
            "roomId": 2,
            "startHour": 15,
            "startMinutes": 35,
            "endHour": 16,
            "endMinutes": 5,
            "abstract": "In the fast-paced world of data-driven architectural solutions, efficient data organization plays a vital role in data engineering. In the recent years, ArmSoft has initiated the process of migrating their clients' data to the cloud environment. During the presentation the challenges and benefits of managing the data in the cloud will be discussed. Moreover, different considerations involved in data migration and what plays a critical role in ensuring a smooth and effective transition will be presented. Sharing our own experience may provide valuable insights for companies wishing to grow their businesses to the data world of cloud technologies."
          },
          {
            "id": 150,
            "speaker": "Shahane Tigranyan",
            "title": "Deep Neural Networks Generalization and Fine-Tuning for 12-lead ECG Classification",
            "roomId": 4,
            "startHour": 15,
            "startMinutes": 35,
            "endHour": 16,
            "endMinutes": 5,
            "abstract": "Numerous studies are aimed at diagnosing heart diseases based on 12-lead electrocardiographic (ECG) records using deep learning methods. These studies usually use specific datasets that differ in size and parameters, such as patient metadata, number of doctors annotating ECGs, types of devices for ECG recording, data preprocessing techniques, etc. It is well-known that high quality deep neural networks trained on one ECG dataset do not necessarily perform well on another dataset or clinical settings. In this paper, we propose a methodology to improve the quality of heart disease prediction regardless of the dataset by training neural networks on a variety of datasets with further fine-tuning for the specific dataset. To show its applicability, we train different neural networks on a large private dataset TIS containing various ECG records from multiple hospitals and on a relatively small public dataset PTB-XL. We demonstrate that training the networks on a large dataset and fine-tuning it on a small dataset from another source outperforms the networks trained only on one small dataset. We also show how the ability of a deep neural networks to generalize allows to improve classification quality of more diseases."
          },
          {
            "id": 160,
            "key": "break",
            "title": "Coffee Break",
            "roomId": 0,
            "startHour": 16,
            "startMinutes": 5,
            "endHour": 16,
            "endMinutes": 30,
            "abstract": ""
          },
          {
            "id": 170,
            "speaker": "Mark Hamazaspyan",
            "title": "Diffusion-Enhanced PatchMatch: A Framework for Arbitrary Style Transfer With Diffusion Models",
            "roomId": 1,
            "startHour": 16,
            "startMinutes": 30,
            "endHour": 17,
            "endMinutes": 0,
            "abstract": "Diffusion models have gained immense popularity in recent years due to their impressive ability to generate high-quality images. The opportunities that diffusion models provide are numerous, from text-to-image synthesis to image restoration and enhancement, as well as image compression and inpainting. However, expressing image style in words can be a challenging task, making it difficult for diffusion models to generate images with specific style without additional optimization techniques. In this paper, we present a novel method, Diffusion-Enhanced PatchMatch (DEPM), that leverages Stable Diffusion for style transfer without any finetuning or pretraining. DEPM captures high-level style features while preserving the fine-grained texture details of the original image. By enabling the transfer of arbitrary styles during inference, our approach makes the process more flexible and efficient. Moreover, its optimization-free nature makes it accessible to a wide range of users."
          },
          {
            "id": 190,
            "speaker": "Gor Hayrapetyan",
            "title": "Boring data engineering",
            "roomId": 2,
            "startHour": 16,
            "startMinutes": 30,
            "endHour": 17,
            "endMinutes": 30,
            "abstract": "As engineers, we enjoy building things. But in this talk, I would like to address the practices and processes that take place before and after building a data engineering solution. To begin with, we will discuss what should be in place before we start to build data pipelines or other solutions, namely, DevOps practices applied to data engineering such as CI/CD and IoC. Then we will focus on monitoring and data quality as post-delivery processes. These are two complementary processes. Not only do we need to make sure that data is flowing through our system but also that it is complete and accurate. Overall, understanding and implementing DevOps practices, monitoring, and data quality in data engineering is crucial for developing and maintaining high-quality data products and platforms."
          },
          {
            "id": 200,
            "speaker": "Hayk Sargsyan",
            "title": "Breast cancer detection through thermal imaging",
            "roomId": 4,
            "startHour": 16,
            "startMinutes": 30,
            "endHour": 17,
            "endMinutes": 0,
            "abstract": "Breast cancer is one of the leading causes of cancer-related deaths among women worldwide. Early detection is critical for effective treatment and improved outcomes.  In this context, thermal imaging has been suggested as a non-invasive, low-risk adjunct screening method for identifying breast cancer. In this study, we present our analyses of thermal imaging data from over 2000 patients who underwent traditional screening methods, including ultrasound, mammography, and biopsy, if needed, at the Erebuni Medical Center. Our analyses employ machine learning algorithms to extract features from the thermal images and evaluate their predictive power in identifying patients at risk of having breast cancer. We find that machine learning-based thermal imaging analysis shows promising results in detecting early breast cancer. We also discuss the challenges and limitations of this approach and suggest future directions for research in this field. Our findings have significant implications for improving breast cancer screening programs, and we believe that machine learning-based thermal imaging analysis can be a valuable addition to existing screening methods for early detection of breast cancer."
          },
          {
            "id": 180,
            "speaker": "Dmitry Temnov",
            "title": "EVA.AI - long way to human-like voice, applications of ML in the industry",
            "roomId": 1,
            "startHour": 17,
            "startMinutes": 5,
            "endHour": 17,
            "endMinutes": 35,
            "abstract": "Eva AI (https://www.evaapp.ai/) is an empathetic artificial intelligence personality, that engages users in conversations through text, voice messages, and AI-generated videos. During the speech, I would like to delve into the evolution of voice generation in Eva AI, from its early beginnings to the innovative generative diffusion models used today. The main points of the speech will be: 1. How we make EVA's voice sound natural and convey different emotions 2. What challenges come with creating a human-like voice 3. What modern approaches we use for the real-time audio messages and calls in our product"
          },
          {
            "id": 210,
            "speaker": "Davit Shahnazaryan",
            "title": "Machine Learning Enabled Disease Subtyping",
            "roomId": 4,
            "startHour": 17,
            "startMinutes": 5,
            "endHour": 17,
            "endMinutes": 35,
            "abstract": "Complex diseases are now not viewed as a single disease, but rather as a clinical diagnosis determined by molecularly defined characteristics in subsets of patients. Drugs should be developed to work in each of these different subgroups. Disease subtyping is the task of identifying subpopulations with similar characteristics. In this talk, we discuss different ML approaches for disease subtyping and how they can enhance the effectiveness of clinical trials by enabling targeted recruitment and helping reduce uncertainty in an individual’s expected outcome for the drug."
          }
        ],
        "date": "September 8",
        "dateIndex": "1",
        "year": 2022,
        "month": 9,
        "day": 8
      },
      {
        "2": [
          {
            "id": 1200,
            "key": "break",
            "title": "Registration",
            "roomId": 0,
            "startHour": 9,
            "startMinutes": 0,
            "endHour": 10,
            "endMinutes": 0,
            "abstract": ""
          },
          {
            "id": 220,
            "speaker": "Augustin Zidek",
            "title": "[Keynote]\nHighly accurate protein structure prediction with AlphaFold",
            "roomId": 0,
            "startHour": 10,
            "startMinutes": 0,
            "endHour": 11,
            "endMinutes": 0,
            "abstract": "Proteins are essential to life, supporting practically all its functions. They are large complex molecules, made up of chains of amino acids, and what a protein does largely depends on its unique 3D structure. Figuring out what shapes proteins fold into is known as the “protein folding problem”, and has stood as a grand challenge in biology for the past 50 years. AlphaFold has been recognised as a solution to this grand challenge by the organisers of the biennial Critical Assessment of protein Structure Prediction (CASP). This breakthrough demonstrates the impact AI can have on scientific discovery and its potential to dramatically accelerate progress in some of the most fundamental fields that explain and shape our world. In the talk, I will give an introduction in structural biology, give an overview of how AlphaFold works, and finally discuss AlphaFold applications and impact on the scientific community. I will also talk about AlphaFold and its development from an engineering perspective."
          },
          {
            "id": 230,
            "speaker": "Hazarapet Tunanyan",
            "title": "Specialist Diffusion: Plug-and-Play Sample-Efficient Fine-Tuning of Text-to-Image Diffusion Models to Learn Any Unseen Style",
            "roomId": 1,
            "startHour": 11,
            "startMinutes": 5,
            "endHour": 11,
            "endMinutes": 35,
            "abstract": "Specialist Diffusion, a style specific personalized text-to-image model. It is plug-and-play to existing diffusion models and other personalization techniques. It outperform the latest few-shot personalization alternatives of diffusion models such as Textual Inversion and DreamBooth, in terms of learning highly sophisticated styles with ultra-sample-efficient tuning."
          },
          {
            "id": 240,
            "speaker": "Sipan Muradyan",
            "title": "Creating your own version of ChatGPT with LangChain",
            "roomId": 2,
            "startHour": 11,
            "startMinutes": 5,
            "endHour": 11,
            "endMinutes": 35,
            "abstract": "In this practical session, we'll dive into the LangChain framework. LangChain provides methods for integrating existing Large Language Models (LLMs) into a distinctive, personalized chatbot. I'll guide you through its features, processes, and demonstrate how to create your own version of ChatGPT. This session is designed to equip attendees with the knowledge and skills needed to leverage LangChain, enabling them to craft personalized AI conversations."
          },
          {
            "id": 250,
            "speaker": "Rafayel Mkrtchyan",
            "title": "ML-based Approaches for Wireless NLOS Localization: Input Representations and Uncertainty Estimation",
            "roomId": 3,
            "startHour": 11,
            "startMinutes": 5,
            "endHour": 11,
            "endMinutes": 35,
            "abstract": "The challenging problem of non-line-of-sight (NLOS) localization is critical for many wireless networking applications. The lack of available datasets has made NLOS localization difficult to tackle with ML-driven methods, but recent developments in synthetic dataset generation have provided new opportunities for research. This paper explores three different input representations: (i) single wireless radio path features, (ii) wireless radio link features (multi-path), and (iii) image-based representations. Inspired by the two latter new representations, we design two convolutional neural networks (CNNs) and we demonstrate that, although not significantly improving the NLOS localization performance, they are able to support richer prediction outputs, thus allowing deeper analysis of the predictions. In particular, the richer outputs enable reliable identification of non-trustworthy predictions and support the prediction of the top-K candidate locations for a given instance. We also measure how the availability of various features (such as angles of signal departure and arrival) affects the model's performance, providing insights about the types of data that should be collected for enhanced NLOS localization. Our insights motivate future work on building more efficient neural architectures and input representations for improved NLOS localization performance, along with additional useful application features."
          },
          {
            "id": 260,
            "key": "break",
            "title": "Coffee Break",
            "roomId": 0,
            "startHour": 11,
            "startMinutes": 35,
            "endHour": 12,
            "endMinutes": 0,
            "abstract": ""
          },
          {
            "id": 270,
            "speaker": "Dzmitry Pranchuk",
            "title": "Synthetic Data Generation via Diffusion Models for Training Discriminative Convolutional Networks",
            "roomId": 1,
            "startHour": 12,
            "startMinutes": 0,
            "endHour": 13,
            "endMinutes": 0,
            "abstract": "These days, diffusion models are the hottest topic in the computer vision community. They're widely used for artistic creations and image inpainting among other applications. However, in this presentation, we're going to shift the focus to an exciting new use of diffusion models - generating synthetic data. We'll explore how this fresh approach can streamline the training of discriminative models."
          },
          {
            "id": 280,
            "speaker": "Loubna Ben Allal",
            "title": "BigCode: Building Large Language Models for Code",
            "roomId": 2,
            "startHour": 12,
            "startMinutes": 0,
            "endHour": 13,
            "endMinutes": 0,
            "abstract": "Language models trained on code have demonstrated remarkable code completion and synthesis abilities from natural language descriptions. BigCode project aims to build code models in an open and responsible approach with support from the ML community. We are working on addressing challenges related to data governance and curation, model architecture, inference, and evaluation. To this end, we released StarCoder a strong Large Language Model for Code with 15.5B parameters and 8K context length. It outperforms existing open models in Python and other programming languages, offers infilling capabilities, fast large-batch inference and incorporates responsible AI practices."
          },
          {
            "id": 290,
            "speaker": "Alexander Serechenko",
            "title": "Machine Learning with Market Data",
            "roomId": 3,
            "startHour": 12,
            "startMinutes": 0,
            "endHour": 12,
            "endMinutes": 30,
            "abstract": "In the rapidly evolving financial landscape, market tick data presents unique challenges and opportunities for data-driven insights. This presentation will explore machine learning techniques tailored for this granular data, emphasizing its application not only in deciphering market patterns and optimizing trading strategies but also in enhancing market surveillance mechanisms. The challenges of feature engineering, the nuances of temporal data sequences, and strategies to mitigate inherent noise will be underscored. The talk concludes with the introduction of the infrastructural solution designed for MLOps specific to market data applications, from development to deployment."
          },
          {
            "id": 300,
            "speaker": "Rafayel Shirakyan",
            "title": "Explainable Churn models",
            "roomId": 3,
            "startHour": 12,
            "startMinutes": 35,
            "endHour": 13,
            "endMinutes": 5,
            "abstract": "In today's data-driven landscape, the gaming and betting industry is continuously seeking innovative methods to mitigate customer churn and enhance player retention. This data science project presentation delves into the development of churn prediction models within the context of a prominent betting company. The primary focus is on constructing predictive models leveraging customer behavior metrics, specifically recency, frequency, and monetary (RFM) indicators. \n\n This academic pursuit adheres to a rigorous analytical methodology, beginning with the collection and preprocessing of extensive user data, including wager histories and engagement patterns. Utilizing a variety of machine learning algorithms, predictive models are meticulously crafted to forecast the likelihood of player churn. Notably, these models are assessed and elucidated through the lens of Shapley values, offering interpretability and insights into the crucial features contributing to churn propensity."
          },
          {
            "id": 310,
            "key": "break",
            "title": "Lunch",
            "roomId": 0,
            "startHour": 13,
            "startMinutes": 5,
            "endHour": 14,
            "endMinutes": 30,
            "abstract": ""
          },
          {
            "id": 320,
            "speaker": "Mariano Kamp",
            "title": "Look Ma, I shrunk BERT (Knowledge Distillation)",
            "roomId": 1,
            "startHour": 14,
            "startMinutes": 30,
            "endHour": 16,
            "endMinutes": 10,
            "abstract": "Large NLP models are dazzling us with their awesome performance. However, their size can pose challenges, making them cumbersome to handle, making it harder to experiment and more expensive. Let’s harness the power of knowledge distillation to use a high-capacity teacher model to help a smaller student model to learn better and faster. Creating a model that is wise beyond its size :) Moreover, the student can even use a different network architecture than the teacher. Let’s use that freedom to craft a model that fits our downstream task perfectly. Not only do we see step-by-step how knowledge distillation works, but we will also mix and match architectural features that are needed for the best model performance on our task. Make your model’s architecture your own."
          },
          {
            "id": 330,
            "speaker": "Semen Sorokin",
            "title": "Document Processing with Zero-Shot Classification and Extraction before and after LLMs in Artemis (by Zero)",
            "roomId": 2,
            "startHour": 14,
            "startMinutes": 30,
            "endHour": 15,
            "endMinutes": 0,
            "abstract": "ZERO Systems provides solutions to augment cognitive processes using Skilled AI Modules (SAMs) to work alongside human workers, offering automation, insights, and proactive assistance using Large Language Models and Generative AI. One of the core ZERO products is Artemis. The solution allows a user to automate document processing flow, meaning help customer classify documents, extract entities, structure information and provide user-friendly interface for document search. Key feature of Artemis system is ability to learn through time using Human Feedback (HITL)."
          },
          {
            "id": 340,
            "speaker": "Daniel Gehrig",
            "title": "Efficient, Data-Driven Perception with Event Cameras",
            "roomId": 3,
            "startHour": 14,
            "startMinutes": 30,
            "endHour": 15,
            "endMinutes": 30,
            "abstract": "Event cameras are bio-inspired sensors that perceive the environment in an entirely different way. Instead of measuring synchronous frames of absolute intensity at fixed intervals, they only measure changes in intensity and do this independently for each pixel, resulting in an asynchronous stream of events. Events thus carry only the compressed visual signal but do this with a micro-second-level latency and temporal resolution, negligible motion blur, and high dynamic range while consuming low power and using a low bandwidth. However, due to their working principle, event cameras output sparse and asynchronous data, which are not directly compatible with standard computer vision algorithms designed for dense frames. Therefore the development of new algorithms to process events, and leverage the advantages of these cameras is at the forefront of active research in event-based vision. In this talk, we will discuss ways to leveraged the avantages of event cameras for high-speed and robust SLAM, low-data computational photography, and low-latency perception for robotics and scene understanding."
          },
          {
            "id": 350,
            "speaker": "Karen Avetisyan",
            "title": "Adversarial Attacks on Language Models: WordPiece Filtration and ChatGPT Synonyms",
            "roomId": 2,
            "startHour": 15,
            "startMinutes": 5,
            "endHour": 15,
            "endMinutes": 35,
            "abstract": "Adversarial attacks on text have gained significant attention in recent years due to their potential to undermine the reliability of NLP models. We present novel black-box character- and word-level adversarial example-generating approaches applicable to BERT-based models. The char-level approach is based on the idea of adding natural typos into a word, according to its WordPiece tokenization. As for the word-level approaches, we present three techniques that make use of synonymous substitute words created by ChatGPT and post-corrected to be in the appropriate grammatical form for the given context. Additionally, we try to minimize the perturbation rate taking into account the damage that each perturbation does to the model. By combining the character-level, word-level approaches and the perturbation rate minimization technique, we achieved a state-of-the-art attack rate. Our best approach works 30-65% faster than the previous best method, Tampers, and has a comparable perturbation rate. Simultaneously, the proposed perturbations retain the semantic similarity between the original and adversarial examples and achieve a relatively low value of Levenshtein distance."
          },
          {
            "id": 360,
            "speaker": "Vladimir Orshulevich",
            "title": "Introduction to Transformers with external memory and its scalability",
            "roomId": 2,
            "startHour": 15,
            "startMinutes": 40,
            "endHour": 16,
            "endMinutes": 10,
            "abstract": "Transformers with external memory are considered as an alternative to increasing the number of parameters or tokens in pre-training datasets in LLM scaling. We will define and describe the transformer model with external memory and review well-known approaches and papers from the last three years. In addition, we will have a look at our internal experiments on how the vector database's retrieval quality affects a model with external memory"
          },
          {
            "id": 370,
            "speaker": "Aram Matinyan",
            "title": "Co-presenter: Nshan Potikyan. Simultaneous object detection and visual tracking",
            "roomId": 3,
            "startHour": 15,
            "startMinutes": 40,
            "endHour": 16,
            "endMinutes": 10,
            "abstract": "Will present how we simultaneously detect and track a cyclist on Raspberry Pi with a unified neural network."
          },
          {
            "id": 380,
            "key": "break",
            "title": "Coffee Break",
            "roomId": 0,
            "startHour": 16,
            "startMinutes": 10,
            "endHour": 16,
            "endMinutes": 30,
            "abstract": ""
          },
          {
            "id": 390,
            "speaker": "Erik Sahakyan",
            "title": "Novel approach to hyperscale GPU compute cluster for AI workloads",
            "roomId": 1,
            "startHour": 16,
            "startMinutes": 30,
            "endHour": 17,
            "endMinutes": 0,
            "abstract": "As the Artificial Intelligence (AI) sector grows and AI models become increasingly complex, it's apparent that traditional Remote Direct Memory Access (RDMA) protocols may not be equipped to handle these mounting demands. Innovating and expanding the capacities of RDMA has emerged as a fundamental necessity in order to keep pace with this burgeoning growth. RDMA has indeed contributed significantly to the improvement of data transfer efficiency. However, inherent constraints, such as the 1K scaling problem, pose serious challenges. Specifically, RDMA performance deteriorates when scaling beyond 1000 nodes of GPUs due to issues like network congestion, thereby hampering efficient data communication. Addressing these limitations requires a fresh approach, which includes programmatically applying different congestion management strategies, acknowledgment procedures, and out-of-order delivery mechanisms to RDMA at runtime. By adopting such dynamic techniques, we can optimize RDMA operations, mitigate the aforementioned scaling problem, and thereby enhance performance and scalability to meet the evolving demands of the AI industry."
          },
          {
            "id": 400,
            "speaker": "Grigory Sapunov",
            "title": "NLP in 2023",
            "roomId": 2,
            "startHour": 16,
            "startMinutes": 30,
            "endHour": 17,
            "endMinutes": 30,
            "abstract": "An overview of inportant results in NLP in 2023"
          },
          {
            "id": 410,
            "speaker": "Alexey Kovalev",
            "title": "Transformers for Reinforcement Learning and Robotics",
            "roomId": 3,
            "startHour": 16,
            "startMinutes": 30,
            "endHour": 17,
            "endMinutes": 0,
            "abstract": "Recently, the use of transformer architectures in reinforcement learning and robotics is acquiring popularity. Decision Transformer and Trajectory Transformer have already become classic works. Another promising direction is the use of multimodal transformers (VIMA, LAVA) for robotics, when the task for the agent is formulated in natural language. The talk will give an overview of the current state of the art and outline promising research directions"
          },
          {
            "id": 420,
            "speaker": "Arman Isajanyan",
            "title": "Enhancing Photo Editing with Content-Based Recommendation System for Stickers",
            "roomId": 1,
            "startHour": 17,
            "startMinutes": 5,
            "endHour": 17,
            "endMinutes": 35,
            "abstract": "Stickers have become a popular form of self-expression in photo editing applications, allowing users to personalize their images and add a touch of creativity. To enhance user experience and engagement, content-based recommendation systems have emerged as a valuable tool for suggesting relevant stickers. To train our recommendation system, we utilized a substantial amount of internal data, including a diverse collection of stickers, metadata, and user interactions. This rich dataset allowed us to build a robust and comprehensive model capable of capturing various sticker categories, styles, and usage patterns. Our approach leverages machine learning algorithms to analyze the visual and semantic attributes of stickers and match them with the user's input image. We conducted rigorous A/B testing, comparing our recommendation system against baseline methods, to evaluate its performance and impact on user satisfaction. The results demonstrate significant improvements in sticker relevancy, diversity, user preference  and user engagement when employing our content-based recommendation system."
          },
          {
            "id": 430,
            "speaker": "Rafayel Darbinyan",
            "title": "Identifying and Disentangling Spurious Features in Pretrained Image Representations",
            "roomId": 3,
            "startHour": 17,
            "startMinutes": 5,
            "endHour": 17,
            "endMinutes": 35,
            "abstract": "Neural networks employ spurious correlations in their predictions, resulting in decreased performance when these correlations do not hold. Recent works suggest fixing pretrained representations and training a classification head that does not use spurious features. We investigate how spurious features are represented in pretrained representations and explore strategies for removing information about spurious features. Considering the Waterbirds dataset and a few pretrained representations, we find that even with full knowledge of spurious features, their removal is not straightforward due to entangled representation. To address this, we propose a linear autoencoder training method to separate the representation into core, spurious, and other features. We propose two effective spurious feature removal approaches that are applied to the encoding and significantly improve classification performance measured by worst group accuracy."
          }
        ],
        "date": "September 9",
        "dateIndex": "2",
        "year": 2022,
        "month": 9,
        "day": 9
      }
    ]
  },
  "organisers": {
    "title": "Organisers",
    "teamTitle": "DataFest Team",
    "organisersList": [],
    "teamList": [
      {
        "name": "Arsen",
        "surname": "Yeghiazaryan",
        "linkedUrl": "https://www.linkedin.com/in/arsen-yeghiazaryan-9abb4721",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1628507913/datafest/speakers/Arsen_Yeghiazaryan_emit7a.jpg"
      },
      {
        "name": "Hrant",
        "surname": "Khachatrian",
        "linkedUrl": "https://www.linkedin.com/in/hrant-khachatrian-b97425206/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1624639416/datafest/speakers/Hrant_Khachatrian_v975hp.jpg"
      },
      {
        "name": "Zaven",
        "surname": "Navoyan",
        "linkedUrl": "https://www.linkedin.com/in/zavennavoyan",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1624639439/datafest/speakers/Zaven_Navoyan_hxmcoc.jpg"
      },
      {
        "name": "Andranik",
        "surname": "Khachatryan",
        "linkedUrl": "https://www.linkedin.com/in/andranik-khachatryan-4b6b82145",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1624639448/datafest/speakers/Andranik_Khachatryan_tjgb2c.jpg"
      }
    ]
  },
  "speakers": {
    "title": "Our <span>Speakers</span>",
    "btnText": "More",
    "aboveText": "",
    "bottomText": "",
    "speakersList": [
      {
        "name": "Loubna",
        "surname": "Ben Allal",
        "position": "ML Engineer at",
        "company": "Hugging Face",
        "linkedUrl": "https://www.linkedin.com/in/loubna-ben-allal-238690152/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1688554343/datafest/DataFest%202023/Speakers/Loubna-Ben-Allal_atbl0r.png"
      },
      {
        "name": "Dzmitry",
        "surname": "Pranchuk",
        "position": "R&D Team Lead at",
        "company": "WANNA",
        "linkedUrl": "https://www.linkedin.com/in/dmitry-pranchuk-885273b5/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1688554342/datafest/DataFest%202023/Speakers/Dzmitry-Pranchuk_at6ren.png"
      },
      {
        "name": "Augustin",
        "surname": "Zidek",
        "position": "Research Engineer at",
        "company": "Google DeepMind",
        "linkedUrl": "#",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1688554342/datafest/DataFest%202023/Speakers/Augustin-Zidek_oyiepr.png"
      },
      {
        "name": "Mariano",
        "surname": "Kamp",
        "position": "Principal Solutions Architect at",
        "company": "Amazon Web Services",
        "linkedUrl": "https://www.linkedin.com/in/mariano-kamp/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1688554343/datafest/DataFest%202023/Speakers/Mariano-Kamp_wrdfhw.png"
      },
      {
        "name": "Michal",
        "surname": "Valko",
        "position": "Research Scientist at",
        "company": "Google DeepMind / Inria / MVA",
        "linkedUrl": "https://www.linkedin.com/in/michalvalko/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1688554342/datafest/DataFest%202023/Speakers/Michal-Valko_gnhsj1.png"
      },
      {
        "name": "Gor",
        "surname": "Hayrapetyan",
        "position": "Senior Data Engineer at",
        "company": "Microsoft",
        "linkedUrl": "https://www.linkedin.com/in/gorhayrapetyan/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1688554342/datafest/DataFest%202023/Speakers/Gor-Hayrapetyan_fs8kas.png"
      },
      {
        "name": "Nikita",
        "surname": "Detkov",
        "position": "CTO / PhD student at",
        "company": "OHMYSYNT / ITMO University",
        "linkedUrl": "https://www.linkedin.com/in/detkovns",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1688554342/datafest/DataFest%202023/Speakers/Nikita-Detkov_hodrvl.png"
      },
      {
        "name": "Vladimir",
        "surname": "Orshulevich",
        "position": "Lead DL research engineer at",
        "company": "Unum.cloud",
        "linkedUrl": "https://www.linkedin.com/in/vladimir-orshulevich-289a7a170/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1688554343/datafest/DataFest%202023/Speakers/Vladimir-Orshulevich_ngjptq.png"
      },
      {
        "name": "Dmitry",
        "surname": "Temnov",
        "position": "Senior Machine Learning Engineer at",
        "company": "EVA.AI",
        "linkedUrl": "https://www.linkedin.com/in/dtemnov",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1688554342/datafest/DataFest%202023/Speakers/Dmitry-Temnov_phigmo.png"
      },
      {
        "name": "Hayk",
        "surname": "Sargsyan",
        "position": "Machine Learning Engineer at",
        "company": "LABZ.ai",
        "linkedUrl": "https://www.linkedin.com/in/hayk-sargsyan-456a6120",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1689068440/datafest/DataFest%202023/Speakers/Hayk-Sargsyan_ymjk1f.png"
      },
      {
        "name": "Mark",
        "surname": "Hamazaspyan",
        "position": "Machine Learning Researcher at",
        "company": "Anania, Metric",
        "linkedUrl": "https://www.linkedin.com/in/mark-hamazaspyan/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1689068440/datafest/DataFest%202023/Speakers/Mark-Hamazaspyan_opwizz.png"
      },
      {
        "name": "Younes",
        "surname": "Belkada",
        "position": "ML Engineer at",
        "company": "Hugging Face",
        "linkedUrl": "https://www.linkedin.com/in/younes-belkada-b1a903145/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1689334847/datafest/DataFest%202023/Speakers/Younes-Belkada_zqqvt6.png"
      },
      {
        "name": "Karen",
        "surname": "Avetisyan",
        "position": "ML Engineer at",
        "company": "CAST",
        "linkedUrl": "https://www.linkedin.com/in/karen-avetisyan-786bb21b4",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1689334847/datafest/DataFest%202023/Speakers/Karen-Avetisyan_xqjq2v.png"
      },
      {
        "name": "Hazarapet",
        "surname": "Tunanyan",
        "position": "Senior ML Scientist at",
        "company": "Picsart Inc.",
        "linkedUrl": "https://www.linkedin.com/in/hazarapet/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1689334847/datafest/DataFest%202023/Speakers/Hazarapet-Tunanyan_a1hj1s.png"
      },
      {
        "name": "Tigran",
        "surname": "Tonoyan",
        "position": "Senior ML Engineer II at",
        "company": "Krisp AI",
        "linkedUrl": "https://www.linkedin.com/in/tigran-tonoyan-b6265884",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1689334847/datafest/DataFest%202023/Speakers/Tigran-Tonoyan_z74zub.png"
      },
      {
        "name": "Erik",
        "surname": "Sahakyan",
        "position": "Senior Hardware Engineer at",
        "company": "Grovf",
        "linkedUrl": "https://www.linkedin.com/in/erik-sahakyan-042322aa/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1689673249/datafest/DataFest%202023/Speakers/Erik-Sahakyan_vnjpr6.png"
      },
      {
        "name": "Shahane",
        "surname": "Tigranyan",
        "position": "ML Engineer at",
        "company": "CAST",
        "linkedUrl": "https://www.linkedin.com/in/shahane-tigranyan-47b096173",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1690362646/datafest/DataFest%202023/Speakers/Shahane-Tigranyan_glu94m.png"
      },
      {
        "name": "Semen",
        "surname": "Sorokin",
        "position": "Lead NLP Engineer at",
        "company": "ZERO Systems",
        "linkedUrl": "https://www.linkedin.com/in/salsorokin/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1690362645/datafest/DataFest%202023/Speakers/Semen-Sorokin_u3i549.png"
      },
      {
        "name": "Arman",
        "surname": "Isajanyan",
        "position": "ML Scientist at",
        "company": "Picsart",
        "linkedUrl": "https://www.linkedin.com/in/arman-isajanyan-b2558613a/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1690362645/datafest/DataFest%202023/Speakers/Arman-Isajanyan_swsacx.png"
      },
      {
        "name": "Alexey",
        "surname": "Kovalev",
        "position": "Researcher at",
        "company": "AIRI",
        "linkedUrl": "#",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1690439408/datafest/DataFest%202023/Speakers/Alexey-Kovalev_moeznp.png"
      },
      {
        "name": "Davit",
        "surname": "Shahnazaryan",
        "position": "Head of Research at",
        "company": "Amaros AI, YSU",
        "linkedUrl": "https://www.linkedin.com/in/davit-shahnazaryan/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1691057851/datafest/DataFest%202023/Speakers/Davit-Shahnazaryan_ebcd9u.png"
      },
      {
        "name": "Sipan",
        "surname": "Muradyan",
        "position": "Senior Machine Learning Specialist at",
        "company": "Portmind",
        "linkedUrl": "https://www.linkedin.com/in/sipan-muradyan/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1691057851/datafest/DataFest%202023/Speakers/Sipan-Muradyan_mqtvpw.png"
      },
      {
        "name": "Aram",
        "surname": "Matinyan",
        "position": "AI Engineer at",
        "company": "Aerodynamics",
        "linkedUrl": "https://www.linkedin.com/in/aram-matinyan/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1691057851/datafest/DataFest%202023/Speakers/Aram-Matinyan_jcwppr.png"
      },
      {
        "name": "Nshan",
        "surname": "Potikyan",
        "position": "AI Team Lead at",
        "company": "Aerodynamics",
        "linkedUrl": "https://www.linkedin.com/in/nshan-potikyan-307bb3131/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1691057851/datafest/DataFest%202023/Speakers/Nshan-Potikyan_jembgi.png"
      },
      {
        "name": "Armen",
        "surname": "Gabrielyan",
        "position": "MLOps Engineer at",
        "company": "Portmind",
        "linkedUrl": "https://www.linkedin.com/in/armen-gabrielyan/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1691057851/datafest/DataFest%202023/Speakers/Armen-Gabrielyan_zosswt.png"
      },
      {
        "name": "Hasmik",
        "surname": "Hakobyan",
        "position": "Software Engineer at",
        "company": "ArmSoft",
        "linkedUrl": "https://www.linkedin.com/in/hasmik-hakobyan/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1691519855/datafest/DataFest%202023/Speakers/Hasmik-Hakobyan_zl6qfm.png"
      },
      {
        "name": "Rafayel",
        "surname": "Shirakyan",
        "position": "Senior Data Scientist at",
        "company": "Digitain",
        "linkedUrl": "https://www.linkedin.com/in/rafayel-shirakyan/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1691520218/datafest/DataFest%202023/Speakers/Rafayel-Shirakyan_sxohqk.png"
      },
      {
        "name": "Fahad",
        "surname": "Khan",
        "position": "Professor at",
        "company": "MBZUAI",
        "linkedUrl": "https://www.linkedin.com/in/fahad-khan-25b3006/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1691521685/datafest/DataFest%202023/Speakers/Fahad-Khan_g3iw1o.png"
      },
      {
        "name": "Artur",
        "surname": "Kadurin",
        "position": "Team lead at",
        "company": "Artificial Intelligence Research Institute",
        "linkedUrl": "https://www.linkedin.com/in/artur-kadurin/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1692287604/datafest/DataFest%202023/Speakers/Artur-Kadurin_rblmfm.png"
      },
      {
        "name": "Alexander",
        "surname": "Serechenko",
        "position": "ML/MLOps engineer and developer at",
        "company": "OneMarketData",
        "linkedUrl": "https://www.linkedin.com/in/alexander-serechenko-84b46161/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1692365557/datafest/DataFest%202023/Speakers/Alexander-Serechenko_egpilo.png"
      },
      {
        "name": "Philipp",
        "surname": "Seidl",
        "position": "PhD candidate at",
        "company": "JKU Linz",
        "linkedUrl": "https://www.linkedin.com/in/phseidl/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1692615802/datafest/DataFest%202023/Speakers/Philipp-Seidl_rrkbis.png"
      },
      {
        "name": "Grigory",
        "surname": "Sapunov",
        "position": "CTO at",
        "company": "Intento",
        "linkedUrl": "https://www.linkedin.com/in/grigorysapunov/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1692615802/datafest/DataFest%202023/Speakers/Grigory-Sapunov_sepbqw.png"
      },
      {
        "name": "Daniel",
        "surname": "Gehrig",
        "position": "Ph.D. Student at",
        "company": "Robotics and Perception Group",
        "linkedUrl": "https://www.linkedin.com/in/daniel-gehrig-942aa714b",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1692703940/datafest/DataFest%202023/Speakers/Daniel-Gehrig_m17rsb.png"
      },
      {
        "name": "Rafayel",
        "surname": "Darbinyan",
        "position": "ML Researcher at",
        "company": "YerevaNN",
        "linkedUrl": "https://www.linkedin.com/in/rafayel-darbinyan",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1693561599/datafest/DataFest%202023/Speakers/Rafayel-Darbinyan_pj3vpl.png"
      },
      {
        "name": "Rafayel",
        "surname": "Mkrtchyan",
        "position": "ML Researcher at",
        "company": "YerevaNN",
        "linkedUrl": "https://www.linkedin.com/in/rafayel-mkrtchyan",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1693474241/datafest/DataFest%202023/Speakers/Rafayel-Mkrtchyan_lg5dge.png"
      },
      {
        "name": "Philipp",
        "surname": "Guevorguian",
        "position": "ML Researcher at",
        "company": "YerevaNN",
        "linkedUrl": "#",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1693474240/datafest/DataFest%202023/Speakers/Philipp-Guevorguian_zxv4xh.png"
      },
        {
        "name": "Vahe",
        "surname": "Andonians",
        "position": "Founder, CTO, CPO at",
        "company": "Cognaize",
        "linkedUrl": "https://www.linkedin.com/in/vaheandonians/",
        "imgUrl": "https://res.cloudinary.com/datafest/image/upload/v1693562893/datafest/DataFest%202023/Speakers/Vahe-Andonians_jsyvsu.png"
      }
    ]
  },
  "location": {
    "title": "Where to find us",
    "lat": "40.193410592591526",
    "lng": "44.504402153484406"
  }
}
